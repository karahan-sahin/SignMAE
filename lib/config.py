# MODEL PARAMS
AXIS = 2
DISTANCE = 'cos' # EUC, COS, OR MAHAL

# IMAGE ENCODER PARAMS
IMAGE_SIZE = 75
NUM_CHANNELS = 1
MODEL_TYPE = 'vivit'
NUM_HIDDEN_LAYERS = 5
NUM_ATTENTION_HEADS = 8
NUM_FRAMES = 100
PATCH_SIZE = 4
TUBELET_SIZE = 8 

# MODEL TYPE
POSE_ENCODER_TYPE = 'vivit'
POSE_ENCODER_MODEL = 'google/vivit-b-16x2'
TEXT_DECODER_MODEL = 'gpt2'
POSE_ENCODER_MODEL = 'posemae_base'
TRANSLATION_MODEL = 'vivit-gpt-model'


# TRAINING PARAMS
TASK_TYPE = 'classification' # TRANSLATION, CLASSIFICATION
DATASET_TYPE = 'bsign22k' # BSIGN22K, AUTSL, ASL FINGER SPELLING
NUM_CLASSES = 768 # 768 for bsign, , 22 for classification
NUM_EPOCHS = 100
BATCH_SIZE = 32
LEARNING_RATE = 1e-4
EPSILON = 1e-8
DEVICE = 'cpu'


# BSIGN22K DATASET PARAMS
DATASET_FILE_PATH = '../../Research/FG 2024/data/mmpose-full'
POSE_DATA_PATH = '../../Research/FG 2024/data/BosphorusSign22k.csv'

# AUTSL DATASET PARAMS


# ASL FINGER SPELLING DATASET PARAMS


# LOGGING PARAMS
LOG_DIR = 'vivit-e=100-b=8-tube=4-16-16_log.txt'